{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Multiclass_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnGfAw7blSfnxfoK+vzjHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucascarter0/DeepLearning.AI-TensorFlow-Certification/blob/main/CNN_Multiclass_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg9nlXXVcVv9"
      },
      "source": [
        "Notebook for Week 4 of the Convolutional Neural Network course - notebook trains a multi-class classifier on the MNIST digit database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxH6a-GGbvWy"
      },
      "source": [
        "import csv\n",
        "from os import getcwd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZY4upJQc8Pp"
      },
      "source": [
        "# Load MNIST data and format it for training in the model\n",
        "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
        "training_images = np.expand_dims(training_images, axis=3)\n",
        "testing_images = np.expand_dims(testing_images, axis=3)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQGYvte3OyA"
      },
      "source": [
        "# Create an ImageDataGenerator to do image augmentation on training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Validation data also using generator, but only to scale image color\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(training_images, training_labels, batch_size=20)\n",
        "\n",
        "validation_generator = validation_datagen.flow(testing_images, testing_labels, batch_size=20)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snc26Ta_4mxk"
      },
      "source": [
        "# Create a model with two convolution layers and two pooling layers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(26, activation='softmax')\n",
        "    ])\n",
        "\n",
        "# Compile Model. Using the sparse crossentropy loss for the multiclass data\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CigxESSP6u7w"
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 98.0%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.97):\n",
        "      print(\"\\nReached 98.0% accuracy, cancelling training\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JblBvbZc3UPB",
        "outputId": "1801bfdd-134e-4bc8-b656-68c752f42225"
      },
      "source": [
        "# Train and evaluate model - train on 10 epochs, but model will exit at 98% accuracy\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    epochs=10,\n",
        "                    callbacks=[myCallback()])\n",
        "\n",
        "model.evaluate(testing_images, testing_labels, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3000/3000 [==============================] - 89s 29ms/step - loss: 0.9122 - accuracy: 0.6919 - val_loss: 0.2484 - val_accuracy: 0.9237\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 88s 29ms/step - loss: 0.4418 - accuracy: 0.8598 - val_loss: 0.1429 - val_accuracy: 0.9536\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 87s 29ms/step - loss: 0.3511 - accuracy: 0.8905 - val_loss: 0.1431 - val_accuracy: 0.9546\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 87s 29ms/step - loss: 0.3182 - accuracy: 0.9025 - val_loss: 0.1665 - val_accuracy: 0.9520\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 87s 29ms/step - loss: 0.3174 - accuracy: 0.9039 - val_loss: 0.1343 - val_accuracy: 0.9627\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 86s 29ms/step - loss: 0.3149 - accuracy: 0.9047 - val_loss: 0.1874 - val_accuracy: 0.9554\n",
            "Epoch 7/10\n",
            "2586/3000 [========================>.....] - ETA: 11s - loss: 0.3184 - accuracy: 0.9043"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsKmTxdW3Zkn"
      },
      "source": [
        "%matplotlib inline\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "fig, (ax0, ax1) = plt.subplots(nrows=2, figsize=(10, 10))\n",
        "ax0.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "ax0.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "ax0.title('Training and validation accuracy')\n",
        "ax0.legend()\n",
        "\n",
        "ax1.plot(epochs, loss, 'r', label='Training Loss')\n",
        "ax1.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "ax1.title('Training and validation loss')\n",
        "ax1.legend()\n",
        "\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}